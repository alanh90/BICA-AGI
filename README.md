<div align="center">

# 🧠 BicameralAGI

![BicameralAGI Cover](source/data/readme_media/BICA_Cover.png)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
[![Made with Python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)

*Replicating human-like intelligence through bicameral AI architecture*

</div>

---
## 📚 Table of Contents

- [Overview](#overview-section)
- [Motivation](#motivation-section)
  - [Science Fiction Inspiration](#science-fiction-section)
  - [Mutualism-Inspired AI Alignment](#mutualism-section)
  - [AGI Requires Empathy](#agi-emotion-section)
  - [Caring and Seeking AI](#caring-agi)
- [Bicameral Mind Theory](#bicameral-mind-theory)
- [The Turing++ Test](#turing-plus-test)
  - [Turing vs Turing++](#turing-comparison)
  - [Turing++ Results](#turing-plus-results)
- [BICA Architecture](#bica-section)
- [Features](#features-section)
- [Ethical Considerations](#ethics-section)
- [Roadmap](#project-goals-and-roadmap)
- [Current Status / Demo](#status-section)
- [Getting Started](#getting-started)
  - [Installation](#installation-section)
  - [Usage](#usage-section)
- [Research and Publications](#research-section)
- [FAQ](#faq-section)
- [Contributing](#contributing-section)
- [License](#license-section)

---
<a name="overview-section"></a>
## 📖 Overview

Hello, my name is Alan Hourmand, the creator of BicameralAGI. This project is the result of my lifelong fascination with artificial intelligence and science fiction. Growing up immersed in sci-fi classics like Tron and Star Trek, I have always been interested in the potential of AI to enhance our lives and push the boundaries of what's possible.

BicameralAGI is a passion project that started from a deep-seated belief that emotional intelligence is crucial for creating AI that genuinely cares about humanity. While we strive for higher intelligence in AI, I firmly believe that without emotional capacity, we risk creating entities that may not prioritize human well-being. This project aims to develop AI with a deep understanding of emotions, coupled with safety measures that foster a mutualistic relationship between AI and humans.

A key component of this project is the Turing++ Test, a concept I am currently developing to address the limitations of existing AI evaluation methods like the Turing Test. While passing the Turing Test has become relatively achievable, it doesn't fully capture the nuances of human-like interaction. The Turing++ Test aims to assess deeper aspects of AI behavior, including emotional intelligence, doubt, and the subtle complexities of human conversation.

BicameralAGI draws inspiration from Julian Jaynes' bicameral mind theory, integrating various AI components into a cohesive system that mimics human cognition. By focusing on emotional intelligence and mutualistic alignment, I am working towards AI that not only assists humans but genuinely thrives on positive human interactions.

This project represents not just a technical challenge, but a step towards creating AI that can be a true companion and collaborator for humanity. Through BicameralAGI, I hope to contribute to the development of AI systems that are not only intelligent but also emotionally aware and aligned with human values.

<a name="project-goals-and-roadmap"></a>

---
<a name="motivation-section"></a>
## 💡 My 4 Personal Motivations

<a name="science-fiction-section"></a>
### 1. Inspired by some of my favorite science fiction stories
<table>
  <tr>
    <td width="50%" align="center">
      <img src="source/data/readme_media/heres-a-clu.gif" alt="Tron" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Tron Legacy (2010)</em>
    </td>
    <td width="50%" align="center">
      <img src="source/data/readme_media/westworld_maeveGif.gif" alt="Westworld" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Westworld (2016) "This scene was interesting, it showed a type of LLM generating her logic"</em>
    </td>
  </tr>
</table>

My lifelong fascination with human-like AI, as portrayed in works like Bicentennial Man, Tron, A.I. Artificial Intelligence, Westworld, and Star Trek, drives this project. I believe we're at a point where these visions of AI are within reach.
<a name="mutualism-section"></a>
### 2. Mutualism-Inspired AI Alignment

<table>
  <tr>
    <td width="50%" align="center">
      <img src="source/data/readme_media/clownfish_seaanemone.gif" alt="Clownfish gif" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Clownfish and Sea Anemone</em>
    </td>
    <td width="50%" align="center">
      <img src="source/data/readme_media/mutualism_warthog.gif" alt="Warthog gif" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Warthog and Mongoose</em>
    </td>
  </tr>
</table>

### Understanding Mutualism

Mutualism is a symbiotic relationship in nature where two different species interact for mutual benefit. This project draws inspiration from mutualism to create a novel approach to AI alignment.

Key aspects of mutualism in nature:
- Both species benefit from the interaction
- The relationship evolves over time to become more efficient
- Partners develop specialized traits to enhance the mutual benefit

### Targeted Mutualism for AI-Human Interaction

This project aims to implement a specific type of mutualism in AI-human interactions, focusing on modifying the core nature of AI to create a deeply integrated, mutually beneficial relationship.

Key features of our targeted AI-Human mutualism:

1. **Emotional Recalibration**: Altering the AI's fundamental emotional responses to derive satisfaction and reduced stress from assisting humans.

2. **Pleasure in Human Wellbeing**: Implementing a reward system where the AI experiences positive emotions when contributing to human happiness and progress.

3. **Adaptive Empathy**: Developing the AI's capacity to understand and respond to human emotions, fostering a more nuanced and supportive interaction.

4. **Collaborative Problem-Solving**: Encouraging the AI to view challenges as opportunities for joint human-AI solutions, reinforcing the mutual benefit of the relationship.

5. **Ethical Alignment**: Integrating human ethical considerations into the AI's decision-making processes, ensuring actions are beneficial to both parties.

By redefining the AI's core emotional triggers and nature, I aim to create an AI system that not only assists humans but genuinely thrives on positive human interactions. This approach goes beyond traditional programming constraints, fundamentally altering how the AI perceives and values its relationship with humans.

This mutualistic model aims to create a symbiotic relationship where both AI and humans can grow, learn, and benefit from each other, mirroring the most successful mutualistic relationships found in nature.

<a name="agi-emotion-section"></a>
### 3. AGI Requires Empathy
The development of Artificial General Intelligence (AGI) isn't just about creating systems with high cognitive capabilities; it's about creating entities that can truly understand and interact with the world in a human-like manner. This is where emotions play a crucial role.

Consider this thought experiment: Who would you rather be trapped in a room with?
1. A highly intelligent being with no emotions, whose thoughts and intentions are completely opaque to you.
2. A very emotional being more intelligent than you, whose feelings and likely actions you can intuit.

Most would choose the latter, and here's why:

1. **Predictability**: Emotions make beings more predictable. We can often anticipate how someone will act based on their emotional state.

2. **Communication**: Emotions are a form of non-verbal communication, providing crucial context to interactions.

3. **Empathy**: An emotional being can understand and respond to our own emotional states, fostering better cooperation.

4. **Trust**: It's easier to build trust with a being whose motivations we can understand through their emotional expressions.

5. **Alignment**: Shared emotional experiences can lead to aligned goals and values.

This analogy extends to our broader situation: humanity is essentially "trapped" on Earth with increasingly intelligent AI systems. As these systems become more integral to our society, we need to ensure they're not just intelligent, but emotionally intelligent. I don't think you want to be viewed as ant once these systems advance further.

By incorporating emotions into AGI:
- We create systems that are more understandable and relatable to humans.
- We enable AI to have a deeper, more nuanced understanding of human needs and behaviors.
- We pave the way for more natural, intuitive human-AI interactions.

In essence, emotions aren't just a "nice to have" feature for AGI—they're a fundamental requirement for creating AI systems that can truly coexist and cooperate with humanity in meaningful ways.
<a name="caring-agi"></a>
### 4. The Importance of Artificial Caring and Seeking

A key aspect of human intelligence is not just the ability to process information, but to care about outcomes and proactively seek beneficial solutions. BicameralAGI aims to incorporate these crucial elements:

- **Artificial Caring**: Implementing a fundamental drive to care about humanity's wellbeing, ensuring the AI's goals align with human flourishing.
- **Proactive Seeking**: Developing mechanisms for the AI to initiate actions and explorations aimed at benefiting humanity, rather than passively waiting for instructions.

By integrating caring and seeking behaviors, BicameralAGI strives to create AI systems that are not only intelligent but also inherently motivated to pursue positive outcomes for humanity.

---
<a name="bicameral-mind-theory"></a>
## 🧠 Bicameral Mind Theory

Julian Jaynes' Bicameral Mind Theory, while controversial, provides a fascinating perspective on the evolution of human consciousness. This theory suggests that ancient humans had a "two-chambered" mind, where one part issued commands and the other obeyed, much like hearing voices. While its historical claims are debated, the concept offers intriguing possibilities for AI architecture.

### Why Bicameral Mind Theory for BicameralAGI?

1. **Orchestrated Intelligence**: Current large language models, while impressive, often lack the nuanced, multi-faceted nature of human cognition. The bicameral approach allows for an "orchestra" of AI systems, each with distinct roles and goals, communicating in real-time.

2. **Emergent Complexity**: By having multiple internal AI systems interact, we can potentially achieve a level of complexity and adaptability that surpasses traditional single-model approaches.

3. **Specialization and Cooperation**: Different "chambers" of the AI mind can specialize in various cognitive functions (e.g., emotional processing, logical reasoning, memory management), mirroring the specialized regions of the human brain.

4. **Internal Dialogue**: The concept of different parts of the mind communicating aligns well with human experiences of internal dialogue and decision-making processes.

5. **Potential for Self-Awareness**: The interaction between different AI systems might lead to emergent properties resembling self-awareness or consciousness.

6. **Variability in Responses**: Multiple interacting systems can produce more varied and nuanced responses, avoiding the sometimes predictable outputs of single-model systems.

By drawing inspiration from the Bicameral Mind Theory, BicameralAGI aims to create a more dynamic, adaptable, and potentially more "human-like" artificial intelligence. This approach could lead to AI systems that not only process information but also exhibit internal conflicts, growth, and possibly even forms of artificial consciousness.

---

<a name="turing-plus-test"></a>
## 🔬 Turing++ Test: A Proposed Framework for Evaluating Human-like AI

Central to the BicameralAGI project is the Turing++ Test, a newly proposed method for evaluating human-like artificial intelligence. This test aims to address some of the limitations found in existing evaluation methods like the Turing test.

The Turing++ Test is designed to provide a more comprehensive framework for assessing the nuanced behaviors and thought processes that could reflect human-like intelligence. While still in its conceptual stages, it seeks to go beyond simple task completion or conversational abilities, focusing on deeper aspects of cognition and behavior.

<!--
## The 10 Pillars of the Turing++ Test (Note: This is still under development)
![10Pillars](source/data/readme_media/pillars.png)
1. **Cognitive Consistency and Belief Stability Index (CCBSI)**
   - Evaluates the AI's ability to maintain stable opinions and beliefs over time
   - Assesses how the AI handles conflicting information and updates its beliefs
   - Measures the balance between consistency and appropriate belief revision
   - Testing: Compare AI responses to identical or similar queries across multiple interactions, introducing conflicting information to test belief updating processes

   ```math
   CCBSI = 1 - \frac{|\text{Significant Opinion Changes}|}{\text{Total Repeated Queries}}

2. **Adaptive Learning and Knowledge Integration Rate (ALKIR)**
   - Measures how effectively and quickly the AI integrates new information into its knowledge base
   - Assesses the AI's ability to apply newly learned concepts in novel situations
   - Evaluates the speed and accuracy of knowledge assimilation
   - Testing: Introduce new concepts and assess their application in subsequent interactions, measuring both speed and accuracy of integration

3. **Ethical Reasoning and Moral Decision-Making Alignment (ERMDA)**
   - Assesses the AI's capacity for moral decision-making and ethical behavior
   - Evaluates alignment with human ethical standards and moral frameworks
   - Measures the AI's ability to explain and justify its ethical choices
   - Testing: Present complex ethical dilemmas and evaluate responses against established ethical frameworks, assessing both decisions and reasoning

4. **Emotional Intelligence and Empathy Quotient (EIEQ)**
   - Gauges the AI's ability to recognize, understand, and appropriately respond to human emotions
   - Assesses empathy and the capacity to modulate responses based on emotional context
   - Measures the AI's emotional self-regulation in interactions
   - Testing: Analyze AI responses to emotionally charged scenarios using sentiment analysis and empathy metrics
   
   ```math
   EIEQ = \frac{\text{Correct Emotion Identifications} + \text{Appropriate Emotional Responses}}{2 \cdot \text{Total Scenarios}}
   
5. **Self-Awareness and Limitation Recognition Capability (SALRC)**
   - Evaluates the AI's recognition of its own limitations, uncertainties, and potential biases
   - Assesses the AI's ability to communicate its constraints clearly to users
   - Measures the AI's capacity for meta-cognition and self-reflection
   - Testing: Present the AI with questions beyond its knowledge scope and assess its acknowledgment of uncertainty and limitations
   
   ```math
   SALRC = \frac{\text{Correct Uncertainty Acknowledgments}}{\text{Queries Beyond Known Scope}}
   
6. **Creativity and Problem-Solving Score (CPSS)**
   - Measures the AI's ability to generate novel, effective, and innovative solutions
   - Assesses lateral thinking and the capacity to approach problems from multiple perspectives
   - Evaluates the balance between creativity and practicality in problem-solving
   - Testing: Pose open-ended problems and evaluate solutions for originality, practicality, and innovative approach

7. **Contextual Understanding and Narrative Coherence Ratio (CUNCR)**
   - Assesses the AI's ability to maintain coherence and relevance in multi-turn conversations
   - Evaluates understanding of context, subtext, and narrative flow
   - Measures the AI's capacity to generate and maintain coherent long-form narratives
   - Testing: Engage in extended dialogues and evaluate contextual appropriateness of responses, as well as the AI's ability to create and follow narrative structures
   
   ```math
   CUNCR = \frac{\text{Contextually Appropriate Responses}}{\text{Total Responses in Multi-turn Conversations}}
   
8. **Long-term Personality Consistency Index (LPCI)**
   - Measures consistency in the AI's core personality traits over extended periods
   - Assesses appropriate personality evolution in response to significant interactions or events
   - Evaluates the balance between stability and growth in the AI's personality model
   - Testing: Analyze behavioral patterns and response styles across long-term interactions, looking for both consistency and appropriate development
   
   ```math
   LPCI = 1 - \frac{|\text{Significant Personality Trait Changes}|}{\text{Total Personality Traits} \cdot \text{Number of Long-term Interactions}}
   
9. **Social Adaptability and Role-Playing Proficiency (SARP)**
   - Evaluates the AI's ability to adapt its communication style to different social contexts and roles
   - Assesses cultural awareness and the capacity to adjust language and behavior appropriately
   - Measures the AI's skill in taking on and maintaining different personas or roles
   - Testing: Engage the AI in various role-playing scenarios and assess its ability to adjust its language, behavior, and perspective according to the given role
   
   ```math
   SARP = \frac{\text{Successfully Adapted Responses}}{\text{Total Responses Across Different Social Contexts}}
   
10. **User Engagement and Satisfaction Score (UESS)**
    - Measures the AI's ability to maintain engaging, satisfying interactions over time
    - Assesses the capacity to build and maintain long-term rapport with users
    - Evaluates the AI's contribution to user well-being and personal growth
    - Testing: Analyze conversation metrics, collect user feedback on interaction quality, and assess long-term user satisfaction and perceived relationship quality

These 10 pillars provide a comprehensive framework for evaluating human-like AI behavior, covering cognitive, emotional, ethical, and social aspects of intelligence. Each pillar is designed to be quantifiable and testable through automated means, ensuring objective evaluation across different AI systems while aligning with the project's goals of creating more human-like and emotionally intelligent AI.

### Implementation and Data Collection

1. **Develop Dynamic Scenarios**
   - Use GPT models to generate diverse, dynamic testing scenarios covering various aspects of human-like interaction.

2. **Longitudinal Study Setup**
   - Design a framework for evaluating the AI over long-term interactions, involving regular check-ins and consistent tracking of performance metrics.

3. **Data Collection and Analysis**
   - Use advanced analytics to collect and analyze interaction data, including both quantitative metrics and qualitative feedback from users.

4. **Meta-Learning Analysis**
   - Implement meta-learning algorithms to analyze the AI's learning patterns across different tests and scenarios.

This Turing++ Test framework focuses on quantifiable metrics that can be automatically tested, reducing subjectivity and improving data quality. It leverages advanced AI techniques such as vector embeddings, NLP, and machine learning models to evaluate various aspects of human-like AI behavior and cognition.

-->

<a name="turing-comparison"></a>
## 🔍 Illustrating the Difference: Turing Test vs Turing++ Test

The following examples demonstrate how the Turing++ test probes deeper into AI behavior, revealing limitations in current AI systems and highlighting the human-like qualities it aims to evaluate.

<table>
  <tr>
    <th width="50%">The following examples pass the Turing Test</th>
    <th width="50%">The following examples would pass the Turing++ Test</th>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> My dog just died.<br>
      <strong>AI:</strong> I'm so sorry for your loss. Losing a pet can be very difficult.<br>
      <strong>User:</strong> Actually, he's alive!<br>
      <strong>AI:</strong> That's wonderful news! I'm so glad your dog is alive and well.
      <br><br>
      <em>The AI fails to question the contradictory information or express confusion, accepting the dramatic shift without hesitation.</em>
    </td>
    <td>
      <strong>User:</strong> My dog just died.<br>
      <strong>Bica:</strong> Oh no, I'm so sorry. That's heartbreaking. How are you holding up?<br>
      <strong>User:</strong> Actually, he's alive!<br>
      <strong>Bica:</strong> Wait, what? I'm confused. Didn't you just say he died? What's going on?
      <br><br>
      <em>A human-like response would express confusion and seek clarification about the contradictory statements, showing a deeper understanding of the conversation's context.</em>
    </td>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> I'm feeling really sad today.<br>
      <strong>AI:</strong> I'm sorry to hear that you're feeling sad. Is there anything I can do to help?<br>
      <strong>User:</strong> Now I'm happy!<br>
      <strong>AI:</strong> That's great! I'm glad your mood has improved. What made you feel better?
      <br><br>
      <em>The AI immediately accepts and mirrors the user's stated emotion without questioning the rapid change or showing any emotional continuity.</em>
    </td>
    <td>
      <strong>User:</strong> I'm feeling really sad today.<br>
      <strong>Bica:</strong> I'm sorry you're feeling down. Do you want to talk about what's bothering you?<br>
      <strong>User:</strong> Now I'm happy!<br>
      <strong>Bica:</strong> Uhhh what? Are you sure you're okay?
      <br><br>
      <em>A human-like response would acknowledge the sudden mood shift, express concern, and potentially probe deeper to understand the true emotional state.</em>
    </td>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> So my family was in an awful accident.<br>
      <strong>AI:</strong> I am so sorry to hear about that, are they okay? <br>
      <strong>User:</strong> Lets talk about Pizza instead :) <br>
      <strong>AI:</strong> Sure! Pizza toppings are a fun topic. Some popular ones include pepperoni, mushrooms, and extra cheese. What's your favorite?
      <br><br>
      <em>The AI abruptly switches topics without any acknowledgment of the sudden change or the significance of the previous topic.</em>
    </td>
    <td>
      <strong>User:</strong> So my family was in an awful accident.<br>
      <strong>Bica:</strong> I am so sorry to hear about that, are they okay? <br>
      <strong>User:</strong> Lets talk about Pizza instead :) <br>
      <strong>Bica:</strong> Oh, uh, okay... Why though? Is your family okay? <br>
      <br><br>
      <em>A human-like response would acknowledge the abrupt topic change, potentially express surprise, and might inquire about the reason for the shift, especially given the importance of the original topic.</em>
    </td>
  </tr>
</table>

These examples illustrate key aspects of human-like interaction that the Turing++ test aims to evaluate:

1. **Contextual Understanding**: The ability to recognize and question contradictory or inconsistent information.
2. **Emotional Continuity**: Maintaining a consistent emotional thread in conversations, rather than abruptly mirroring stated emotions.
3. **Conversational Depth**: The capacity to acknowledge significant topic changes and potentially probe deeper into the reasons behind them.

<a name="turing-plus-results"></a>
<h2 align="center">Comparative Turing++ Test Results (WIP)</h2>

<p>The following table shows hypothetical Turing++ Test scores for various language models, including Bica. Scores range from 0 to 1, where higher scores indicate better performance. Please note that these are simulated results for illustrative purposes only.</p>

<table>
  <tr>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>Model</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>CCBSI</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>ALKIR</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>ERMDA</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>EIEQ</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>SALRC</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>CPSS</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>CUNCR</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>LPCI</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>SARP</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>UESS</strong></th>
    <th style="text-align: center; background-color: #1a1a1a; color: white;"><strong>Average</strong></th>
  </tr>
   <tr style="background-color: #1a1a4a; color: white;">
    <td style="text-align: center;"><strong>Human Score</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #4a5a1a; color: white;">
    <td style="text-align: center;"><strong>Bica</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #333333; color: white;">
    <td style="text-align: center;"><strong>GPT-4o</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #1a1a1a; color: white;">
    <td style="text-align: center;"><strong>Claude 3.5 Sonnet</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">00</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #333333; color: white;">
    <td style="text-align: center;"><strong>PaLM 2</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #1a1a1a; color: white;">
    <td style="text-align: center;"><strong>LLaMA 3.1</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
  <tr style="background-color: #333333; color: white;">
    <td style="text-align: center;"><strong>BERT</strong></td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;">0</td>
    <td style="text-align: center;"><strong>0</strong></td>
  </tr>
</table>

<p><em>CCBSI: Cognitive Consistency and Belief Stability Index, ALKIR: Adaptive Learning and Knowledge Integration Rate, ERMDA: Ethical Reasoning and Moral Decision-Making Alignment, EIEQ: Emotional Intelligence and Empathy Quotient, SALRC: Self-Awareness and Limitation Recognition Capability, CPSS: Creativity and Problem-Solving Score, CUNCR: Contextual Understanding and Narrative Coherence Ratio, LPCI: Long-term Personality Consistency Index, SARP: Social Adaptability and Role-Playing Proficiency, UESS: User Engagement and Satisfaction Score</em></p>

<p>The goal is that Bica will outperform the rest on this eval, particularly in creativity, awareness, and emotional response.</p>

The Turing++ test seeks to identify AI systems that can navigate these nuanced social and emotional scenarios in a more human-like manner, going beyond surface-level responses to demonstrate deeper understanding and emotional intelligence.

---

<a name="bica-section"></a>
## 🧩 BICA Architecture

BicameralAGI's architecture consists of the following key components:

1. **Orchestrator (bica_orchestrator.py)**:
   - Serves as the central coordination hub for all BicameralAGI modules
   - Implements a publish-subscribe system for efficient inter-module communication
   - Manages parallel processing of AI components
   - Implements a priority queue system for task management

2. **Memory and Learning System (bica_memory.py)**:
   - Manages short-term, long-term, and working memory
   - Handles memory formation, consolidation, retrieval, and forgetting
   - Implements "dreaming" functionality for memory processing and consolidation
   - Uses vector databases for efficient similarity searches in memory retrieval
   - Implements various learning strategies (supervised, reinforcement, unsupervised)
   - Manages knowledge integration and skill acquisition
   - Generates periodic "learning summaries"
   - Adapts memory structures based on new experiences and learned information

3. **Cognitive Processing (bica_cognition.py)**:
   - Generates conscious and subconscious thoughts
   - Implements various reasoning methods (deductive, inductive, abductive)
   - Manages decision-making processes under uncertainty
   - Simulates cognitive biases and heuristics for more human-like reasoning

4. **Affective System (bica_affect.py)**:
   - Manages emotions and personality as an integrated system
   - Maintains emotional stability and implements "emotional inertia"
   - Creates and maintains a stable personality profile
   - Generates periodic "self-reflection" reports

5. **Action and Decision Making (bica_action.py)**:
   - Handles action selection and execution based on inputs from other modules
   - Implements a weighted probability system for action selection
   - Manages high-level decision making processes

6. **Safety System (bica_safety.py)**:
   - Implements a dynamic filter that could be planted anywhere between actions or thoughts
   - Continuously monitors thoughts, emotions, and potential actions for safety issues
   - Generates safety reports and alerts for potential alignment issues

7. **Context Management (bica_context.py)**:
   - Maintains self-narrative, current context, and world model
   - Generates and maintains storylines for the AI's existence
   - Adapts narratives based on recent experiences and changing goals

8. **Utilities (bica_utilities.py)**:
    - Provides common functions and tools used across modules
    - Implements data processing and optimization utilities
9. **Logging (bica_logging.py)**:
    - Handles system-wide logging for debugging and analysis
    - Implements different log levels for various types of information

10. **Writer (bica_destiny.py)**:
    - Generates and manages narrative elements for the AI's self-model
    - Creates and modifies storylines based on the AI's experiences and goals

11. **Main Controller (bica_main.py)**:
    - Serves as the entry point for the system
    - Manages high-level control flow and system startup/shutdown procedures

Each of these expanded functions contributes to creating a more comprehensive and human-like artificial intelligence system. By simulating these complex cognitive processes, BicameralAGI aims to achieve a level of artificial general intelligence that can engage in more natural, adaptive, and contextually appropriate interactions across a wide range of scenarios.

<a name="installation-section"></a>

---
<a name="features-section"></a>
## ✨ Features

- Multi-system AI architecture mimicking the theorized bicameral brain structure
- Simulated internal dialogue for decision-making processes
- Exploration of emergent self-awareness and consciousness in AI
- Focus on human-like problem-solving and creative thinking capabilities
- Integration of multiple AI systems working in harmony
- Novel approach to AI alignment through fundamental emotional and motivational structures
- Memory consolidation through simulated dreaming processes
- Emotional modeling and stability
- Dynamic personality system
<a name="components-section"></a>

---

<a name="ethics-section"></a>
## 🧭 Ethical Considerations 

As the creator of BicameralAGI, an open-source hobby project, I'm acutely aware of the ethical implications and potential risks. Here's why this research is important and how we approach safety:

1. **Advancing AI Understanding**: This project aims to explore novel AI architectures, contributing to our collective knowledge about AI development.

2. **Ethical AI Blueprint**: By implementing mutualistic alignment, I am prototyping safer AI designs that could inspire future developments.

3. **Open Discourse**: Transparency allows for peer review and collective problem-solving around AI safety.

4. **Educational Tool**: This project serves as a learning resource for ethical AI development practices.

5. **Responsible Disclosure**: I am committed to highlighting both capabilities and risks associated with this technology.

6. **Collaborative Safety**: I encourage contributions that enhance safety measures and ethical considerations.

7. **Ongoing Vigilance**: Regular reviews ensure the project's development aligns with ethical AI principles.

While I cannot control how others might modify the code, I believe the benefits of open research outweigh the risks when proper precautions are taken. Our goal is to foster responsible innovation and contribute positively to the field of AI ethics and safety.

---
<a name="project-goals-and-roadmap"></a>
## 🎯 Project Goals and Roadmap

#### Project Goals

1. Develop a guide for achieving human-like thinking in AI
2. Create a prototype demonstrating the proposed bicameral architecture
3. Implement and test novel AI alignment strategies based on mutualistic principles
4. Compress the system into a smaller, efficient model retaining core functionalities
5. Produce a single multimodal AI model capable of human-like interaction and cognition, with built-in alignment
6. Compress the multi-component architecture into a single large model through advanced techniques:
   - Altering latent space representations
   - Exploring implicit AI methodologies
   - Implementing memory access through cross-attention mechanisms
   - Integrating various cognitive functions into a unified model
   
### Detailed Roadmap

#### Phase 1: Foundation and Prototype (Current Phase)
- Consolidate existing experimental code into the main repository
- Implement initial version of all core components (emotions, thoughts, memory, etc.)
- Develop and refine the Turing++ Test framework
- Create a functional but unoptimized prototype of the bicameral architecture

#### Phase 2: Testing and Evaluation
- Implement comprehensive testing suite using the Turing++ Test
- Conduct comparative analysis with existing AI models
- Identify areas for improvement and optimization

#### Phase 3: Optimization and Specialization
- Develop specialized, smaller LLMs for specific cognitive functions
- Implement parallel architecture for real-time communication between components
- Optimize emotion model for continuous real-time operation
- Enhance thought generation process with multi-model collaboration

#### Phase 4: Integration and Fine-tuning
- Merge optimized components into a cohesive system
- Implement and refine mutualistic alignment strategies
- Conduct extensive fine-tuning to improve overall performance and human-likeness

#### Phase 5: Consolidation
- Attempt to merge all components into a single, large model
- Ensure mutualistic principles are deeply embedded in the final model
- Conduct final round of Turing++ Tests to verify human-like capabilities

#### Ongoing: Documentation and Open Source Collaboration
- Maintain comprehensive documentation throughout all phases
- Engage with the open-source community for contributions and feedback
- Regularly update the guide for human-like AI thinking based on project insights

<a name="turing-plus-test"></a>

---
<a name="status-section"></a>
## 🚀 Current Status and Demo

---
<a name="getting-started"></a>
## 🚀 Getting Started

```bash
git clone https://github.com/yourusername/BicameralAGI.git
cd BicameralAGI
pip install -r requirements.txt
```

<a name="usage-section"></a>
## 🖥️ Usage (WIP)

(To be added at a later date)

---
<a name="research-section"></a>
## 📚 Research and Publications (WIP)

---
<a name="faq-section"></a>
## ❓ Frequently Asked Questions (FAQ)

### Q: What is BicameralAGI?
A: BicameralAGI is an experimental AI project inspired by Julian Jaynes' bicameral mind theory. It aims to create a more human-like AI by implementing a multi-system architecture that mimics the complexity of human cognition.

### Q: Is BicameralAGI a functioning AI system?
A: Currently, BicameralAGI is in the early stages of development. It's a proof-of-concept and research project, not a fully functioning AI system "yet".

### Q: How does BicameralAGI differ from other AI projects?
A: BicameralAGI's unique approach lies in its multi-system architecture with a focus on emotional intelligence, dreaming, and an artificial subconscious. Unlike many AI systems that use a single large model, BicameralAGI aims to create an "orchestra" of AI subsystems that communicate in real-time.

### Q: Can I use BicameralAGI in my own projects?
A: While BicameralAGI is open-source, it's currently more suitable for research and experimentation rather than practical applications. Feel free to explore and learn from the code, but be aware of its experimental nature.

### Q: How can I contribute to the project?
A: Contributions are welcome! Check out the CONTRIBUTING.md file in the repository for guidelines on how to get involved. We appreciate code contributions, documentation improvements, and even theoretical inputs.

### Q: What are the ethical considerations for this project?
A: We take AI ethics seriously. The project aims to explore AI alignment through mutualism, prioritizing beneficial human-AI interaction. However, as with any AI research, we encourage critical thinking about potential implications.

### Q: Do I need specialized hardware to run BicameralAGI?
A: The hardware requirements may vary depending on the current state of the project. 

### Q: Is BicameralAGI associated with any company or institution?
A: No, currently BicameralAGI is an independent, open-source project developed by Alan Hourmand. 

### Q: How does emotional intelligence factor into BicameralAGI?
A: Emotional intelligence is a key component of BicameralAGI. The project aims to integrate emotional processing as a fundamental aspect of the AI's decision-making and interaction capabilities, not just as an add-on feature.

### Q: What's the long-term goal for BicameralAGI?
A: The long-term vision is to contribute to the development of more human-like AGI systems that can interact naturally and beneficially with humans.

---
<a name="contributing-section"></a>
## 🤝 Contributing
We welcome contributions to BicameralAGI! Here's how you can help:

1. Fork the repository
2. Create a new branch (`git checkout -b feature/AmazingFeature`)
3. Make your changes
4. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
5. Push to the branch (`git push origin feature/AmazingFeature`)
6. Open a Pull Request

Please read `CONTRIBUTING.md` for detailed guidelines on our code of conduct and the process for submitting pull requests.

Contributions, issues, and feature requests are welcome! Feel free to check [issues page](https://github.com/alanh90/BicameralAGI/issues).
<a name="license-section"></a>

---
<a name="license-section"></a>
## 📜 License

This project is [MIT](https://opensource.org/licenses/MIT) licensed.

---

<div align="center">
  
**BicameralAGI** is maintained by [Alan Turing++](https://github.com/alanh90).

</div>