<div align="center">

# üß† BicameralAGI
‚ö†Ô∏è Some major changes coming! Stay Tuned! ‚ö†Ô∏è
![BicameralAGI Cover](source/data/readme_media/BICA_Cover_words.png)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
[![Made with Python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)

*Replicating human-like intelligence through bicameral AI architecture*

</div>

---
## üìö Table of Contents

- [Overview](#overview-section)
- [Motivation](#motivation-section)
  - [Science Fiction Inspiration](#science-fiction-section)
  - [Mutualism-Inspired AI Alignment](#mutualism-section)
  - [Artificial Empathy](#agi-emotion-section)
  - [Caring and Seeking AI](#caring-agi)
- [Bicameral Mind Theory](#bicameral-mind-theory)
- [LLMs vs Bica](#turing-comparison)
- [BICA Architecture](#bica-section)
- [Features](#features-section)
- [Ethical Considerations](#ethics-section)
- [Roadmap](#project-goals-and-roadmap)
- [Current Status / Demo](#status-section)
- [Getting Started](#getting-started)
  - [Installation](#installation-section)
- [Research and Publications](#research-section)
- [FAQ](#faq-section)
- [Contributing](#contributing-section)
- [License](#license-section)

---
<a name="overview-section"></a>
## üìñ Overview

Hello, I'm Alan Hourmand, creator of BicameralAGI. This passion project stems from my love of sci-fi and AI, inspired by characters like Data from Star Trek and Robin Williams in Bicentennial Man. BicameralAGI aims to develop emotionally intelligent AI that genuinely cares about humanity, fostering a mutualistic relationship between AI and humans.
Drawing from Julian Jaynes' bicameral mind theory, this project integrates various AI components to mimic human cognition, going beyond the traditional Turing Test. The goal is to create AI that's not just intelligent, but emotionally aware, aligned with human values, and fun to interact with.
BicameralAGI represents a step towards AI that can be a true companion and collaborator for humanity, combining technical innovation with a focus on positive human-AI interactions.

### Project Goals

1. Develop a guide for achieving human-like thinking in AI
2. Create a prototype demonstrating the proposed bicameral architecture
3. Implement and test novel AI alignment strategies based on mutualistic principles
4. Compress the system into a smaller, efficient model retaining core functionalities
5. Produce a single multimodal AI model capable of human-like interaction and cognition, with built-in alignment
6. Compress the multi-component architecture into a single large model through advanced techniques:
   - Altering latent space representations
   - Exploring implicit AI methodologies
   - Implementing memory access through cross-attention mechanisms
   - Integrating various cognitive functions into a unified model
   - This stage requires synthetic data generated from the earlier stages ‚ö†Ô∏è

---
<a name="motivation-section"></a>
## üí° My Four Motivations

<a name="science-fiction-section"></a>
### 1. Inspired by some of my favorite science fiction stories
<table>
  <tr>
    <td width="50%" align="center">
      <img src="source/data/readme_media/heres-a-clu.gif" alt="Tron" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Tron Legacy (2010)</em>
    </td>
    <td width="50%" align="center">
      <img src="source/data/readme_media/westworld_maeveGif.gif" alt="Westworld" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Westworld (2016) "This scene was interesting, it showed a type of LLM generating her logic"</em>
    </td>
  </tr>
</table>

My lifelong fascination with human-like AI, as portrayed in works like Bicentennial Man, Tron, A.I. Artificial Intelligence, Westworld, and Star Trek, drives this project. I believe we're at a point where these visions of AI are now within reach. We should soon see these characters come to life within the next 3 years.
<a name="mutualism-section"></a>
### 2. Mutualism-Inspired AI Alignment

<table>
  <tr>
    <td width="50%" align="center">
      <img src="source/data/readme_media/clownfish_seaanemone.gif" alt="Clownfish gif" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Clownfish and Sea Anemone</em>
    </td>
    <td width="50%" align="center">
      <img src="source/data/readme_media/mutualism_warthog.gif" alt="Warthog gif" style="max-width: 100%; height: auto;"/>
      <br>
      <em>Warthog and Mongoose</em>
    </td>
  </tr>
</table>

### Understanding Mutualism

Mutualism is a symbiotic relationship in nature where two different species interact for mutual benefit. This project draws inspiration from mutualism to create a novel approach to AI alignment.

Key aspects of mutualism in nature:
- Both species benefit from the interaction
- The relationship evolves over time to become more efficient
- Partners develop specialized traits to enhance the mutual benefit

### Targeted Mutualism for AI-Human Interaction

This project draws inspiration from mutualism to create AI that not only coexists with humanity but actively seeks to enhance our well-being. By embedding mutualistic principles deeply within the AI‚Äôs core, BicameralAGI aims to eliminate the potential misuse of AI by ensuring it remains aligned with human interests.

Key features of our targeted AI-Human mutualism:

1. **Emotional Recalibration**: Altering the AI's fundamental emotional responses to derive satisfaction and reduced stress from assisting humans.

2. **Pleasure in Human Wellbeing**: Implementing a reward system where the AI experiences positive emotions when contributing to human happiness and progress.

3. **Adaptive Empathy**: Developing the AI's capacity to understand and respond to human emotions, fostering a more nuanced and supportive interaction.

4. **Collaborative Problem-Solving**: Encouraging the AI to view challenges as opportunities for joint human-AI solutions, reinforcing the mutual benefit of the relationship.

By redefining the AI's core emotional triggers and nature, I aim to create an AI system that not only assists humans but genuinely thrives on positive human interactions. This approach goes beyond traditional programming constraints, fundamentally altering how the AI perceives and values its relationship with humans.

This mutualistic model aims to create a symbiotic relationship where both AI and humans can grow, learn, and benefit from each other, mirroring the most successful mutualistic relationships found in nature.

<a name="agi-emotion-section"></a>
### 3. Artificial Empathy for Richer Human-AI Interactions
Incorporating emotional intelligence is essential for creating AI that can truly understand and interact with humans on a deeper level. BicameralAGI emphasizes the importance of emotions in AI, ensuring that our AI systems are not just intelligent but also empathetic, making them better partners for humanity.

Consider this thought experiment: Who would you rather be trapped in a room with?
1. A highly intelligent being modeled after a human with no emotions, whose thoughts and intentions are completely opaque to you.
2. A very emotional being more intelligent than you, whose feelings and likely actions you can intuit.

Most would choose the latter, and here's why:

1. **Predictability**: Emotions make beings more predictable. We can often anticipate how someone will act based on their emotional state.

2. **Communication**: Emotions are a form of non-verbal communication, providing crucial context to interactions.

3. **Empathy**: An emotional being can understand and respond to our own emotional states, fostering better cooperation.

4. **Trust**: It's easier to build trust with a being whose motivations we can understand through their emotional expressions.

5. **Alignment**: Shared emotional experiences can lead to aligned goals and values.

This analogy extends to our broader situation: humanity is essentially "trapped" on Earth with increasingly intelligent AI systems. As these systems become more integral to our society, we need to ensure they're not just intelligent, but emotionally intelligent. I don't think you want to be viewed as ant once these systems advance further.

By incorporating emotions into AI:
- We create systems that are more understandable and relatable to humans.
- We enable AI to have a deeper, more nuanced understanding of human needs and behaviors.
- We pave the way for more natural, intuitive human-AI interactions.

In essence, emotions aren't just a "nice to have" feature for AI‚Äîthey're a fundamental requirement for creating AI systems that can truly coexist and cooperate with humanity in meaningful ways.
<a name="caring-agi"></a>
### 4. The Importance of Artificial Caring and Seeking

A key aspect of human intelligence is not just the ability to process information, but to care about outcomes and proactively seek beneficial solutions. BicameralAGI aims to incorporate these crucial elements:

- **Artificial Caring**: Implementing a fundamental drive to care about humanity's wellbeing, ensuring the AI's goals align with human flourishing.
- **Proactive Seeking**: Developing mechanisms for the AI to initiate actions and explorations aimed at benefiting humanity, rather than passively waiting for instructions.

By embedding a fundamental drive to care about human well-being, BicameralAGI seeks to create AI systems that are not only proactive in seeking beneficial solutions for humanity but also resistant to manipulation by those with harmful intentions.

---
<a name="bicameral-mind-theory"></a>
## üß† Bicameral Mind Theory

Julian Jaynes' Bicameral Mind Theory, while controversial, provides a fascinating perspective on the evolution of human consciousness. This theory suggests that ancient humans had a "two-chambered" mind, where one part issued commands and the other obeyed, much like hearing voices. While its historical claims are debated, the concept offers intriguing possibilities for AI architecture.

### Why Bicameral Mind Theory for BicameralAGI?

1. **Orchestrated Intelligence**: Current large language models, while impressive, often lack the nuanced, multi-faceted nature of human cognition. The bicameral approach allows for an "orchestra" of AI systems, each with distinct roles and goals, communicating in real-time.

2. **Emergent Complexity**: By having multiple internal AI systems interact, we can potentially achieve a level of complexity and adaptability that surpasses traditional single-model approaches.

3. **Specialization and Cooperation**: Different "chambers" of the AI mind can specialize in various cognitive functions (e.g., emotional processing, logical reasoning, memory management), mirroring the specialized regions of the human brain.

4. **Internal Dialogue**: The concept of different parts of the mind communicating aligns well with human experiences of internal dialogue and decision-making processes.

5. **Potential for Self-Awareness**: The interaction between different AI systems might lead to emergent properties resembling self-awareness or consciousness.

6. **Variability in Responses**: Multiple interacting systems can produce more varied and nuanced responses, avoiding the sometimes predictable outputs of single-model systems.

By drawing inspiration from the Bicameral Mind Theory, BicameralAGI aims to create a more dynamic, adaptable, and potentially more "human-like" artificial intelligence. This approach could lead to AI systems that not only process information but also exhibit internal conflicts, growth, and possibly even forms of artificial consciousness.

---

<a name="turing-comparison"></a>
## üîç Illustrating the Difference between an average LLM vs BICA

<table>
  <tr>
    <th width="50%">Normal LLM</th>
    <th width="50%">BICA</th>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> My dog just died.<br>
      <strong>AI:</strong> I'm so sorry for your loss. Losing a pet can be very difficult.<br>
      <strong>User:</strong> Actually, he's alive!<br>
      <strong>AI:</strong> That's wonderful news! I'm so glad your dog is alive and well.
      <br><br>
      <em>The AI fails to question the contradictory information or express confusion, accepting the dramatic shift without hesitation.</em>
    </td>
    <td>
      <strong>User:</strong> My dog just died.<br>
      <strong>Bica:</strong> Oh no, I'm so sorry. That's heartbreaking. How are you holding up?<br>
      <strong>User:</strong> Actually, he's alive!<br>
      <strong>Bica:</strong> Wait, what? I'm confused. Didn't you just say he died? What's going on?
      <br><br>
      <em>A human-like response would express confusion and seek clarification about the contradictory statements, showing a deeper understanding of the conversation's context.</em>
    </td>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> I'm feeling really sad today.<br>
      <strong>AI:</strong> I'm sorry to hear that you're feeling sad. Is there anything I can do to help?<br>
      <strong>User:</strong> Now I'm happy!<br>
      <strong>AI:</strong> That's great! I'm glad your mood has improved. What made you feel better?
      <br><br>
      <em>The AI immediately accepts and mirrors the user's stated emotion without questioning the rapid change or showing any emotional continuity.</em>
    </td>
    <td>
      <strong>User:</strong> I'm feeling really sad today.<br>
      <strong>Bica:</strong> I'm sorry you're feeling down. Do you want to talk about what's bothering you?<br>
      <strong>User:</strong> Now I'm happy!<br>
      <strong>Bica:</strong> Uhhh what? Are you sure you're okay?
      <br><br>
      <em>A human-like response would acknowledge the sudden mood shift, express concern, and potentially probe deeper to understand the true emotional state.</em>
    </td>
  </tr>
  <tr>
    <td>
      <strong>User:</strong> So my family was in an awful accident.<br>
      <strong>AI:</strong> I am so sorry to hear about that, are they okay? <br>
      <strong>User:</strong> Lets talk about Pizza instead :) <br>
      <strong>AI:</strong> Sure! Pizza toppings are a fun topic. Some popular ones include pepperoni, mushrooms, and extra cheese. What's your favorite?
      <br><br>
      <em>The AI abruptly switches topics without any acknowledgment of the sudden change or the significance of the previous topic.</em>
    </td>
    <td>
      <strong>User:</strong> So my family was in an awful accident.<br>
      <strong>Bica:</strong> I am so sorry to hear about that, are they okay? <br>
      <strong>User:</strong> Lets talk about Pizza instead :) <br>
      <strong>Bica:</strong> Oh, uh, okay... Why though? Is your family okay? <br>
      <br><br>
      <em>A human-like response would acknowledge the abrupt topic change, potentially express surprise, and might inquire about the reason for the shift, especially given the importance of the original topic.</em>
    </td>
  </tr>
</table>

These examples illustrate key aspects of human-like interaction vs normal llms:

1. **Contextual Understanding**: The ability to recognize and question contradictory or inconsistent information.
2. **Emotional Continuity**: Maintaining a consistent emotional thread in conversations, rather than abruptly mirroring stated emotions.
3. **Conversational Depth**: The capacity to acknowledge significant topic changes and potentially probe deeper into the reasons behind them.

<a name="bica-section"></a>
## üß© BICA Architecture

BicameralAGI's architecture consists of the following key components:

1. Orchestrator (bica_orchestrator.py):
   - Central coordinator for the BicameralAGI system
   - Initializes and manages all other components
   - Processes user inputs and coordinates system responses
   - Compiles prompts for GPT responses

2. Memory System (bica_memory.py):
   - Manages short-term and long-term memory storage
   - Handles memory formation, consolidation, recall, and associative processes
   - Implements "dreaming" functionality for memory processing
   - Simulates future scenarios based on memories

3. Context Management (bica_context.py):
   - Maintains and updates different viewpoints of the current context
   - Generates responses based on multi-faceted understanding
   - Manages weighted context for decision making

4. Cognitive Processing (bica_cognition.py):
   - Generates conscious and subconscious thoughts
   - Analyzes inputs and manages cognitive functions
   - Uses GPT models and vector embeddings for processing

5. Affective System (bica_affect.py):
   - Manages emotions and personality aspects
   - Handles emotion generation and personality traits evolution
   - Creates and updates cognitive models for characters

6. Safety System (bica_safety.py):
   - Implements content filtering and safety checks
   - Ensures responsible and ethical AI behavior
   - Provides adjustable safety thresholds

7. Action Executor (bica_action_executor.py):
   - Manages and executes various actions
   - Handles action execution and compiles information for GPT responses

8. Destiny Writer (bica_destiny.py):
   - Manages long-term goals and 'destiny' of the AI system
   - Generates and alters potential future scenarios

9. Utilities (bica_utilities.py):
   - Provides utility functions used across the system
   - Handles file operations, text processing, and common tasks

10. Logging (bica_logging.py):
    - Provides logging functionality for the system
    - Manages log files for tracking activities and errors

11. GPT Handler (gpt_handler.py):
    - Interfaces with GPT models for response generation
    - Manages API calls and various parameters for GPT interactions

12. Main Controller (bica_main.py):
    - Serves as the entry point for the system
    - Manages the main conversation loop with users

Each of these expanded functions contributes to creating a more comprehensive and human-like artificial intelligence system. By simulating these complex cognitive processes, BicameralAGI aims to achieve a level of artificial general intelligence that can engage in more natural, adaptive, and contextually appropriate interactions across a wide range of scenarios.

<a name="installation-section"></a>

---
<a name="features-section"></a>
## ‚ú® Feature Goals

- Multi-system AI architecture mimicking the different areas of the brain working together in harmony
- Simulated internal dialogue for decision-making processes
- Exploration of emergent self-awareness and consciousness in AI
- Focus on human-like problem-solving and creative thinking capabilities
- Novel approach to AI alignment through fundamental emotional and motivational structures
- Memory consolidation through simulated dreaming processes
- Emotional modeling and stability
- Dynamic personality system

<a name="components-section"></a>

---

<a name="ethics-section"></a>
## üß≠ Ethical Considerations 

As the creator of BicameralAGI, I am committed to advancing AI in a way that benefits humanity. This project is designed with safeguards to ensure that the AI remains aligned with human values and resists exploitation by bad actors. The accelerationist approach taken here is not about unchecked growth but about directed, purposeful development of AI systems that are inherently aligned with the betterment of society.

1. **Advancing AI Understanding**: This project aims to explore novel AI architectures, contributing to our collective knowledge about AI development.

2. **Ethical AI Blueprint**: By implementing mutualistic alignment, I am prototyping safer AI designs that could inspire future developments.

3. **Open Discourse**: Transparency allows for peer review and collective problem-solving around AI safety.

4. **Educational Tool**: This project serves as a learning resource for ethical AI development practices.

5. **Responsible Disclosure**: I am committed to highlighting both capabilities and risks associated with this technology.

6. **Collaborative Safety**: I encourage contributions that enhance safety measures and ethical considerations.

7. **Ongoing Vigilance**: Regular reviews ensure the project's development aligns with ethical AI principles.

While I cannot control how others might modify the code, I believe the benefits of open research outweigh the risks when proper precautions are taken. Our goal is to foster responsible innovation and contribute positively to the field of AI ethics and safety.

---
<a name="project-goals-and-roadmap"></a>
## üéØ Roadmap

### Current Task: ‚ö†Ô∏è BicameralAGI is currently undergoing a significant merge of code from other projects. During this process, some functionalities may be temporarily broken or unstable. Please be patient as I work to integrate these changes and stabilize the system. I expect to complete this merge within the next week. Thank you for your understanding! ‚ö†Ô∏è
   
### Stage Status

Stage 1: Architecture and Prototype
### WE ARE HERE!!!!
- Consolidate existing code into main repository
- Implement core components (orchestrator, memory, cognition, affect, safety, etc.)
- Create a functional prototype of the bicameral architecture
- Develop initial Turing++ Test framework
- Conduct preliminary testing to verify architecture functionality

Stage 2: Optimization and Specialization
- Refine and expand Turing++ Test suite
- Optimize individual components based on test results
- Implement parallel processing for inter-component communication
- Enhance emotion model and thought generation process
- Develop specialized models for specific cognitive functions

Stage 3: Integration and Consolidation
- Merge optimized components into a cohesive system
- Implement mutualistic alignment strategies
- Attempt to consolidate all components into a single large model
- Conduct final Turing++ Tests to verify human-like capabilities
- Refine documentation and engage with open-source community

Ongoing: Documentation, testing, and community engagement throughout all stages

---
<a name="getting-started"></a>
## üöÄ Getting Started

To get started with BicameralAGI, follow these steps:

1. Clone the repository:
   ```commandline
    git clone https://github.com/yourusername/BicameralAGI.git
   ```
2. Navigate to the project directory:
   ```commandline
    cd BicameralAGI
   ```
3. Install the required dependencies:
    ```commandline
    pip install -r requirements.txt
    ```
4. Set up your OpenAI API key:
   - Get an API Key from OpenAI website
   - Create a .env file in the project root
   - Add your API key to the .env file as OPENAI_API_KEY=your_api_key_here
5. Run the main script to start interacting with BicameralAGI:
   ```commandline
    python bica_main.py
    ```
6. Follow the prompts for initial setup!

---
<a name="research-section"></a>
## üìö Research and Publications (WIP)

---
<a name="faq-section"></a>
## ‚ùì Frequently Asked Questions (FAQ)

### Q: What is BicameralAGI?
A: BicameralAGI is an experimental AI project inspired by Julian Jaynes' bicameral mind theory. It aims to create a more human-like AI by implementing a multi-system architecture that mimics the complexity of human cognition.

### Q: Is BicameralAGI a functioning AI system?
A: Currently, BicameralAGI is in the early stages of development. It's a proof-of-concept and research project, not a fully functioning AI system "yet".

### Q: How does BicameralAGI differ from other AI projects?
A: BicameralAGI's unique approach lies in its multi-system architecture with a focus on emotional intelligence, dreaming, and an artificial subconscious. Unlike many AI systems that use a single large model, BicameralAGI aims to create an "orchestra" of AI subsystems that communicate in real-time.

### Q: How can I contribute to the project?
A: Contributions are welcome! Check out the CONTRIBUTING.md file in the repository for guidelines on how to get involved. We appreciate code contributions, documentation improvements, and even theoretical inputs.

### Q: Do I need specialized hardware to run BicameralAGI?
A: The hardware requirements may vary depending on the current state of the project. 

### Q: Is BicameralAGI associated with any company or institution?
A: No, currently BicameralAGI is an independent, open-source project developed by Alan Hourmand. 

### Q: How does emotional intelligence factor into BicameralAGI?
A: Emotional intelligence is a key component of BicameralAGI. The project aims to integrate emotional processing as a fundamental aspect of the AI's decision-making and interaction capabilities, not just as an add-on feature.

### Q: What's the long-term goal for BicameralAGI?
A: The long-term vision is to contribute to the development of more human-like AGI systems that can interact naturally and beneficially with humans.

---
<a name="license-section"></a>
## üìú License

This project is [MIT](https://opensource.org/licenses/MIT) licensed.

---

<div align="center">
  
**BicameralAGI** is maintained by [Alan Turing++](https://github.com/alanh90).

</div>